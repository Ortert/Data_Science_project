# Oписание проекта - Проект для «Викишоп» (определение токсичных комментариев)

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других.

## Данные

Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.

## Задача

Обучить модель классифицировать комментарии на позитивные и негативные со значением метрики качества F1 не меньше 0.75

## Используемые библиотеки
*re*, *pandas*, *numpy*, *matplotlib*, *seaborn*, *Pytorch*, *sklearn*, *transformers*, *nltk*, *wordcloud*

## Вывод

В рамках выполнения задачи по обучению модели классифицировать комментарии на позитивные и негативные, было выполнено:
- загружены и проверены на корректность загрузки и отображения исследуемые данные;
- исследовано распределение значений целевого признака 'toxic' - распределение несбалансировано, количество нетоксичных комментариев существенно превышает количество токсичных;
- исследовано среднее и медианное количество слов для токсичных и нетоксичных комментариев: среднее количество слов в нетоксичных комментариях превышает аналогичное в токсичных комментриях, более чем на 30% (68.857665 и 2.677314 соответственно), а медианное значение более чем 60% (37 и 23 соответственно). В связи со значительной разнице в рапсределении количества слов по таргету, прдланается использовать данный признак в процессе обучения.
- выведено "облако слов" с разбивкой по таргету до лемматизации и очистки текста и после. До лемматизации и очистки текста для негативных комменатриев характерны слова 'fuck', 'suck', NIGGER и т.д., для комментариев не имеющих негативного окраса - 'article', 'page', 'Wikipedia', 'Please'. После лемматизации и очистки для негативных комменатриев характерны слова 'fuck', 'suck', 'go' и т.д., для комментариев не имеющих негативного окраса - 'article', 'page', 'please', 'Wikipedia'.
- исследуемые тексты подготовлены к обучению:
а) без помощи модели BERT: тексты лематизированы, очищены и разеделены на обучающую и тестовую выборки
б) с помощью модели BERT подготоволена ораниченная случайная выборка в 20000 экземпляров (ввиду ресурсоемкого преобразования), выборка разеделена на обучающую и тестовую
Обучены и получены предсказания на ранее предобработанном тексте: а) без обработки BERT, с помощью пайплайна и моделей PassiveAggressiveClassifier, LogisticRegression, также переберем различное количество N-грамм для TfidfVectorizer(stop_words='english')). Перебор параметров выполним с помощью метода GridSearchCV. Лучшую метрику f1 = 0.7750 на кросс-валидации показала модель PassiveAggressiveClassifier(max_iter=50) использующая данные преобразованные с помощью TfidfVectorizer(ngram_range=(1, 2), stop_words='english')) Контрольная метрика на тестовой выборке  составила f1_score = 0.7811, что соответсвует ТЗ.  
б) с обработкой  BERT, с помощью пайплайна и моделей PassiveAggressiveClassifier, LogisticRegression. Перебор параметров выполним с помощью метода GridSearchCV. Лучшую метрику f1 = 0.8994 на кросс-валидации показала модель  LogisticRegression(C=0.1, penalty='l1',  solver='liblinear').  Контрольная метрика на тестовой выборке  составила f1_score = 0.9085, что соответсвует ТЗ.
